{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import ast\n",
    "import json\n",
    "import scipy\n",
    "\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# from sklearn.model_selection import train_test_split\n",
    "#from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, r2_score, roc_auc_score, precision_score, recall_score\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_auc_score\n",
    "\n",
    "import lightfm\n",
    "from lightfm import LightFM\n",
    "\n",
    "#import Reviews_combiner_processer\n",
    "#from Reviews_combiner_processer import user_info\n",
    "import ast\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import Reader\n",
    "from surprise import Dataset\n",
    "from surprise.model_selection import cross_validate\n",
    "\n",
    "from surprise import NormalPredictor\n",
    "\n",
    "from surprise import KNNWithMeans\n",
    "from surprise import KNNWithZScore\n",
    "from surprise import KNNBaseline\n",
    "\n",
    "from surprise import SVD\n",
    "from surprise import SVDpp\n",
    "\n",
    "from surprise import NMF\n",
    "from surprise import SlopeOne, CoClustering, BaselineOnly\n",
    "from surprise.accuracy import rmse\n",
    "from surprise import accuracy\n",
    "from surprise.model_selection import GridSearchCV\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "from lightfm import cross_validation\n",
    "from lightfm.evaluation import precision_at_k\n",
    "from lightfm.evaluation import recall_at_k\n",
    "from lightfm.evaluation import auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rating = pd.read_csv('product_ratings_customer.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Product_pid</th>\n",
       "      <th>brand</th>\n",
       "      <th>product_name</th>\n",
       "      <th>product_type</th>\n",
       "      <th>stars</th>\n",
       "      <th>Awards</th>\n",
       "      <th>Clinical_tested</th>\n",
       "      <th>Skintype_normal</th>\n",
       "      <th>Skintype_dry</th>\n",
       "      <th>...</th>\n",
       "      <th>Skinc_Wrinkles</th>\n",
       "      <th>Skinc_Dullness</th>\n",
       "      <th>Skinc_Pores</th>\n",
       "      <th>Skinc_Uneven_Texture</th>\n",
       "      <th>Skinc_Acne</th>\n",
       "      <th>Skinc_Uneven_Tone</th>\n",
       "      <th>Skinc_Dark_Spot</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>ingred_list</th>\n",
       "      <th>Skinc_total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>P57002</td>\n",
       "      <td>fresh</td>\n",
       "      <td>Sugar Lip Balm Sunscreen SPF 15</td>\n",
       "      <td>Lip Balms &amp; Treatments</td>\n",
       "      <td>89.474</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Cera Alba (Beeswax), Ricinus Communis (Castor)...</td>\n",
       "      <td>['Cera Alba (Beeswax)', 'Ricinus Communis (Cas...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>P462699</td>\n",
       "      <td>Glow Recipe</td>\n",
       "      <td>Plum Plump™ Hyaluronic Acid Serum</td>\n",
       "      <td>Face Serums</td>\n",
       "      <td>91.804</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Water, Glycerin, Propanediol, Pentylene Glycol...</td>\n",
       "      <td>['Water', 'Glycerin', 'Propanediol', 'Pentylen...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>P463948</td>\n",
       "      <td>SEPHORA COLLECTION</td>\n",
       "      <td>Holographic Effect Mask</td>\n",
       "      <td>Face Masks</td>\n",
       "      <td>82.858</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Aqua (Water), Glycerin, Butylene Glycol, Cerat...</td>\n",
       "      <td>['Aqua (Water)', 'Glycerin', 'Butylene Glycol'...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>P439926</td>\n",
       "      <td>Drunk Elephant</td>\n",
       "      <td>A-Passioni™ Retinol Cream</td>\n",
       "      <td>Face Serums</td>\n",
       "      <td>82.162</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Water, Glycerin, Coco-Caprylate, Stearic Acid,...</td>\n",
       "      <td>['Water', 'Glycerin', 'Coco-Caprylate', 'Stear...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>P447791</td>\n",
       "      <td>Glow Recipe</td>\n",
       "      <td>Avocado Melt Retinol Eye Sleeping Mask</td>\n",
       "      <td>Eye Creams &amp; Treatments</td>\n",
       "      <td>84.896</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Water, Glycerin, Propanediol, Glyceryl Stearat...</td>\n",
       "      <td>['Water', 'Glycerin', 'Propanediol', 'Glyceryl...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 Product_pid               brand  \\\n",
       "0           0      P57002               fresh   \n",
       "1           1     P462699         Glow Recipe   \n",
       "2           2     P463948  SEPHORA COLLECTION   \n",
       "3           3     P439926      Drunk Elephant   \n",
       "4           4     P447791         Glow Recipe   \n",
       "\n",
       "                             product_name             product_type   stars  \\\n",
       "0         Sugar Lip Balm Sunscreen SPF 15   Lip Balms & Treatments  89.474   \n",
       "1       Plum Plump™ Hyaluronic Acid Serum              Face Serums  91.804   \n",
       "2                 Holographic Effect Mask               Face Masks  82.858   \n",
       "3               A-Passioni™ Retinol Cream              Face Serums  82.162   \n",
       "4  Avocado Melt Retinol Eye Sleeping Mask  Eye Creams & Treatments  84.896   \n",
       "\n",
       "   Awards  Clinical_tested  Skintype_normal  Skintype_dry  ...  \\\n",
       "0       1                0                1             1  ...   \n",
       "1       0                1                1             1  ...   \n",
       "2       0                0                1             1  ...   \n",
       "3       1                1                1             1  ...   \n",
       "4       0                1                1             1  ...   \n",
       "\n",
       "   Skinc_Wrinkles  Skinc_Dullness  Skinc_Pores  Skinc_Uneven_Texture  \\\n",
       "0               0               0            0                     0   \n",
       "1               1               0            0                     0   \n",
       "2               0               0            0                     0   \n",
       "3               1               0            0                     0   \n",
       "4               0               0            0                     0   \n",
       "\n",
       "   Skinc_Acne  Skinc_Uneven_Tone  Skinc_Dark_Spot  \\\n",
       "0           0                  0                0   \n",
       "1           0                  0                0   \n",
       "2           0                  0                0   \n",
       "3           0                  0                1   \n",
       "4           0                  0                0   \n",
       "\n",
       "                                         ingredients  \\\n",
       "0  Cera Alba (Beeswax), Ricinus Communis (Castor)...   \n",
       "1  Water, Glycerin, Propanediol, Pentylene Glycol...   \n",
       "2  Aqua (Water), Glycerin, Butylene Glycol, Cerat...   \n",
       "3  Water, Glycerin, Coco-Caprylate, Stearic Acid,...   \n",
       "4  Water, Glycerin, Propanediol, Glyceryl Stearat...   \n",
       "\n",
       "                                         ingred_list  Skinc_total  \n",
       "0  ['Cera Alba (Beeswax)', 'Ricinus Communis (Cas...            0  \n",
       "1  ['Water', 'Glycerin', 'Propanediol', 'Pentylen...            2  \n",
       "2  ['Aqua (Water)', 'Glycerin', 'Butylene Glycol'...            0  \n",
       "3  ['Water', 'Glycerin', 'Coco-Caprylate', 'Stear...            2  \n",
       "4  ['Water', 'Glycerin', 'Propanediol', 'Glyceryl...            1  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pro.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pro = pd.read_csv('product_post_eda.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_product_select_clean.join(df_product_select['details']).to_csv('Final_product_df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  NLP for reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nlp = df_rating.drop_duplicates(subset=['UserNickname', 'ProductId']).dropna(subset=['UserNickname']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "312562"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "lemma = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def review_text_lemma(reviewText):\n",
    "    reviews = \"\".join([w for w in reviewText if w not in string.punctuation])\n",
    "    tokens = re.split('\\W+', reviews)\n",
    "    review_clean = [lemma.lemmatize(ws) for ws in tokens if ws not in stopwords]\n",
    "    review_cleaner = \" \".join(review_clean)\n",
    "    return review_cleaner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nlp['review_kw'] = df_nlp['ReviewText'].apply(lambda x: review_text_lemma(str(x).lower()))\n",
    "df_nlp['title_kw'] = df_nlp['Title'].apply(lambda x: review_text_lemma(str(x).lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rating_clean = df_nlp.drop(['Badges', 'BadgesOrder', 'ContentLocale',\n",
    "            'ContextDataValues', 'ContextDataValuesOrder', 'eyecolor', 'haircolor'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Combination    139327\n",
       "No info         58963\n",
       "Dry             49200\n",
       "Normal          33874\n",
       "Oily            31198\n",
       "Name: skintype, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rating_clean.skintype.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rating_userskintype = df_nlp[['UserNickname', 'skintype']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserNickname</th>\n",
       "      <th>skintype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lizziebae</td>\n",
       "      <td>Combination</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BelleOh</td>\n",
       "      <td>Combination</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BelLaCafe</td>\n",
       "      <td>Dry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bluekrait</td>\n",
       "      <td>Combination</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fairginger</td>\n",
       "      <td>No info</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  UserNickname     skintype\n",
       "0    lizziebae  Combination\n",
       "1      BelleOh  Combination\n",
       "2    BelLaCafe          Dry\n",
       "3    bluekrait  Combination\n",
       "4   fairginger      No info"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rating_userskintype.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'Badges', 'BadgesOrder', 'ContentLocale',\n",
       "       'ContextDataValues', 'ContextDataValuesOrder', 'Id', 'IsRatingsOnly',\n",
       "       'IsRecommended', 'ProductId', 'Rating', 'ReviewText', 'SubmissionId',\n",
       "       'SubmissionTime', 'Title', 'TotalNegativeFeedbackCount',\n",
       "       'TotalPositiveFeedbackCount', 'UserNickname', 'Dict_context',\n",
       "       'skintype', 'eyecolor', 'skinconcerns', 'haircolor', 'skintone',\n",
       "       'review_kw', 'title_kw'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nlp.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(max_features = 8000)\n",
    "X = tfidf.fit_transform(df_nlp['review_kw']).toarray()[:5000]\n",
    "y = df_nlp['Rating'][:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5000, 8000), (5000,))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state=12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3500, 8000), (3500,))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(criterion='entropy', n_estimators=20)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators = 20, \n",
    "                            criterion = 'entropy') \n",
    "                              \n",
    "model.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 12,   2,   0,   1,  78],\n",
       "       [  3,   5,   2,   4,  72],\n",
       "       [  3,   2,   1,  12,  90],\n",
       "       [  0,   0,   0,  15, 225],\n",
       "       [  0,   0,   2,   8, 963]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test) \n",
    "from sklearn.metrics import confusion_matrix \n",
    "  \n",
    "cm = confusion_matrix(y_test, y_pred) \n",
    "cm "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Surprise Remmender System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vanilla = pd.read_csv('vanilla_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>UserNickname</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>lizziebae</td>\n",
       "      <td>P420224</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>BelleOh</td>\n",
       "      <td>P420224</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>BelLaCafe</td>\n",
       "      <td>P420224</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>bluekrait</td>\n",
       "      <td>P420224</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>fairginger</td>\n",
       "      <td>P420224</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 UserNickname ProductId  Rating\n",
       "0           0    lizziebae   P420224       5\n",
       "1           1      BelleOh   P420224       5\n",
       "2           2    BelLaCafe   P420224       5\n",
       "3           3    bluekrait   P420224       5\n",
       "4           4   fairginger   P420224       5"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_vanilla.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vanilla_clean = df_vanilla.drop_duplicates(subset=['UserNickname', 'ProductId']).dropna(subset=['UserNickname']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(316548, 312562)"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_vanilla), len(df_vanilla_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "312562"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_vanilla_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_binary = df_vanilla_clean\n",
    "df_binary['Rating_bin'] = np.where(df_binary['Rating']>2, 1, 0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vanilla_matrix = df_vanilla_clean.pivot(index='UserNickname', \n",
    "                    columns='ProductId', values = 'Rating').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vanilla_matrix_binary = df_binary.pivot(index='UserNickname', \n",
    "                    columns='ProductId', values = 'Rating_bin').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regular rating stars dataset\n",
    "reader = Reader(rating_scale=(0, 1))\n",
    "data = Dataset.load_from_df(df_vanilla_clean[['UserNickname', 'ProductId', 'Rating']], reader)\n",
    "data_bin = Dataset.load_from_df(df_binary[['UserNickname', 'ProductId', 'Rating_bin']], reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_rmse</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>test_time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithm</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SVDpp</th>\n",
       "      <td>0.320670</td>\n",
       "      <td>36.592079</td>\n",
       "      <td>0.815952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVD</th>\n",
       "      <td>0.322079</td>\n",
       "      <td>18.412205</td>\n",
       "      <td>0.551274</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           test_rmse   fit_time  test_time\n",
       "Algorithm                                 \n",
       "SVDpp       0.320670  36.592079   0.815952\n",
       "SVD         0.322079  18.412205   0.551274"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SVD model\n",
    "SVD_res = []\n",
    "# Iterate over all algorithms\n",
    "for algo in [SVD(), SVDpp()]:\n",
    "    \n",
    "    # Perform cross validation\n",
    "    cv_fold = cross_validate(algo, data_bin, measures=['RMSE'], cv=5, verbose=False)\n",
    "    \n",
    "    # Get results & append algorithm name\n",
    "    results = pd.DataFrame.from_dict(cv_fold).mean(axis=0)\n",
    "    results = results.append(pd.Series([str(algo).split(' ')[0].split('.')[-1]], index=['Algorithm']))\n",
    "    SVD_res.append(results)\n",
    "\n",
    "surprise_results_svd = pd.DataFrame(SVD_res).set_index('Algorithm').sort_values('test_rmse')\n",
    "surprise_results_svd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_rmse</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>test_time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithm</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SlopeOne</th>\n",
       "      <td>0.355642</td>\n",
       "      <td>2.573128</td>\n",
       "      <td>0.691683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NormalPredictor</th>\n",
       "      <td>0.410729</td>\n",
       "      <td>0.535604</td>\n",
       "      <td>0.578424</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 test_rmse  fit_time  test_time\n",
       "Algorithm                                      \n",
       "SlopeOne          0.355642  2.573128   0.691683\n",
       "NormalPredictor   0.410729  0.535604   0.578424"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normal Predictor & Slope One\n",
    "\n",
    "NP_Slope_res = []\n",
    "# Iterate over all algorithms\n",
    "for algo in [NormalPredictor(), SlopeOne()]:\n",
    "    \n",
    "    # Perform cross validation\n",
    "    cv_fold = cross_validate(algo, data_bin, measures=['RMSE'], cv=5, verbose=False)\n",
    "    \n",
    "    # Get results & append algorithm name\n",
    "    results = pd.DataFrame.from_dict(cv_fold).mean(axis=0)\n",
    "    results = results.append(pd.Series([str(algo).split(' ')[0].split('.')[-1]], index=['Algorithm']))\n",
    "    NP_Slope_res.append(results)\n",
    "\n",
    "surprise_results_nmp_slope = pd.DataFrame(NP_Slope_res).set_index('Algorithm').sort_values('test_rmse')\n",
    "surprise_results_nmp_slope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_rmse</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>test_time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithm</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BaselineOnly</th>\n",
       "      <td>0.320764</td>\n",
       "      <td>1.586316</td>\n",
       "      <td>0.634806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CoClustering</th>\n",
       "      <td>0.351816</td>\n",
       "      <td>28.563486</td>\n",
       "      <td>0.523282</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              test_rmse   fit_time  test_time\n",
       "Algorithm                                    \n",
       "BaselineOnly   0.320764   1.586316   0.634806\n",
       "CoClustering   0.351816  28.563486   0.523282"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Co-Clustering\n",
    "CoC_res = []\n",
    "# Iterate over all algorithms\n",
    "for algorithm in [CoClustering(), BaselineOnly()]:\n",
    "    \n",
    "    # Perform cross validation\n",
    "    cv_fold = cross_validate(algorithm, data_bin, measures=['RMSE'], cv=5, verbose=False)\n",
    "    \n",
    "    # Get results & append algorithm name\n",
    "    results = pd.DataFrame.from_dict(cv_fold).mean(axis=0)\n",
    "    results = results.append(pd.Series([str(algorithm).split(' ')[0].split('.')[-1]], index=['Algorithm']))\n",
    "    CoC_res.append(results)\n",
    "\n",
    "surprise_results_coc = pd.DataFrame(CoC_res).set_index('Algorithm').sort_values('test_rmse')\n",
    "surprise_results_coc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "0.3206515253594061\n",
      "{'bsl_options': {'method': 'sgd'}}\n"
     ]
    }
   ],
   "source": [
    "# Baseline only and SVDpp are the best\n",
    "# Grid Search for Baseline only first\n",
    "\n",
    "algo = BaselineOnly()\n",
    "\n",
    "param_grid = {'bsl_options':{ 'method': ['als', 'sgd']} } \n",
    "      #      'n_epochs': [5, 10, 15],\n",
    "       #     'reg_u': [5, 10, 15],\n",
    "       #     'reg_i': [5, 10, 15]}}\n",
    "              \n",
    "gs = GridSearchCV(BaselineOnly, param_grid, measures=['rmse', 'mae'], cv=5)\n",
    "\n",
    "gs.fit(data_bin)\n",
    "\n",
    "# best RMSE score\n",
    "print(gs.best_score['rmse'])\n",
    "\n",
    "# combination of parameters that gave the best RMSE score\n",
    "print(gs.best_params['rmse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "0.3204831653460892\n",
      "{'bsl_options': {'method': 'sgd', 'n_epochs': 25, 'reg': 0.2, 'reg_i': 0.005}}\n"
     ]
    }
   ],
   "source": [
    "algo = BaselineOnly()\n",
    "\n",
    "param_grid = {'bsl_options':{ 'method': ['sgd'],\n",
    "                             \n",
    "      'n_epochs': [15, 20, 25],\n",
    "       'reg': [0.02, 0.2, 2],\n",
    "       'reg_i': [0.005, 0.5]}}\n",
    "              \n",
    "gs = GridSearchCV(BaselineOnly, param_grid, measures=['rmse', 'mae'], cv=5)\n",
    "\n",
    "gs.fit(data_bin)\n",
    "\n",
    "# best RMSE score\n",
    "print(gs.best_score['rmse'])\n",
    "\n",
    "# combination of parameters that gave the best RMSE score\n",
    "print(gs.best_params['rmse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using sgd...\n"
     ]
    }
   ],
   "source": [
    "# Using Baseline Only to make predictions\n",
    "trainset, testset = train_test_split(data_bin, test_size = 0.3)\n",
    "alg = BaselineOnly(bsl_options = { 'method':'sgd', 'n_epochs': 25, 'reg':0.2, 'reg_i':0.005})\n",
    "alg.fit(trainset)\n",
    "test_pred = alg.test(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "real = []\n",
    "pred = []\n",
    "for i in range(len(testset)):\n",
    "    r = testset[i][2]\n",
    "    p = test_pred[i][3]\n",
    "    real.append(r)\n",
    "    pred.append(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions are continuous\n",
    "# Used 0.5 as a threshold, >0.5 as recommending, <0.5 as not recommending\n",
    "pred_bin = []\n",
    "for i in range(len(test_pred)):\n",
    "    predbin = np.where(test_pred[i][3]>0.6, 1, 0)\n",
    "    pred_bin.append(predbin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.877 \n",
      "Precision Score: 0.879 \n",
      "Recall Score: 0.997\n"
     ]
    }
   ],
   "source": [
    "auc_bo = accuracy_score(real, pred_bin)\n",
    "prec_bo = precision_score(real, pred_bin)\n",
    "rec_bo = recall_score(real, pred_bin)\n",
    "print('Accuracy Score:', '{:.3f}'.format(auc_bo), \n",
    "      '\\nPrecision Score:', '{:.3f}'.format(prec_bo), \n",
    "      '\\nRecall Score:', '{:.3f}'.format(rec_bo))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVD pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.32065294829407914\n",
      "{'n_epochs': 25, 'lr_all': 0.005, 'reg_all': 0.4}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'n_epochs': [15, 20, 25], 'lr_all': [0.002, 0.005],\n",
    "              'reg_all': [0.4, 0.6]}\n",
    "gs = GridSearchCV(SVDpp, param_grid, measures=['rmse', 'mae'], cv=5)\n",
    "\n",
    "gs.fit(data_bin)\n",
    "\n",
    "# best RMSE score\n",
    "print(gs.best_score['rmse'])\n",
    "\n",
    "# combination of parameters that gave the best RMSE score\n",
    "print(gs.best_params['rmse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset, testset = train_test_split(data_bin, test_size = 0.3)\n",
    "alg = SVDpp(n_epochs = 25, lr_all = 0.005, reg_all = 0.4)\n",
    "alg.fit(trainset)\n",
    "test_pred = alg.test(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "real = []\n",
    "pred = []\n",
    "for i in range(len(testset)):\n",
    "    r = testset[i][2]\n",
    "    p = test_pred[i][3]\n",
    "    real.append(r)\n",
    "    pred.append(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions are continuous\n",
    "# Used 0.5 as a threshold, >0.5 as recommending, <0.5 as not recommending\n",
    "pred_bin = []\n",
    "for i in range(len(test_pred)):\n",
    "    predbin = np.where(test_pred[i][3]>0.6, 1, 0)\n",
    "    pred_bin.append(predbin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.876 \n",
      "ROC AUC Score: 0.505 \n",
      "Precision Score: 0.878 \n",
      "Recall Score: 0.998\n"
     ]
    }
   ],
   "source": [
    "acu_bo = accuracy_score(real, pred_bin)\n",
    "auc_bo = roc_auc_score(real, pred_bin, average='weighted')\n",
    "prec_bo = precision_score(real, pred_bin)\n",
    "rec_bo = recall_score(real, pred_bin)\n",
    "print('Accuracy Score:', '{:.3f}'.format(acu_bo), \n",
    "      '\\nROC AUC Score:', '{:.3f}'.format(auc_bo),\n",
    "      '\\nPrecision Score:', '{:.3f}'.format(prec_bo), \n",
    "      '\\nRecall Score:', '{:.3f}'.format(rec_bo))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVDpp and Reducing my initial dataset\n",
    "some people only rated a product once and that's difficult to predict. So I'm going to get rid of those users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "jen101            81\n",
       "faeriegirl        45\n",
       "itsryanwithani    44\n",
       "Mitz17            43\n",
       "JennRen44         42\n",
       "                  ..\n",
       "catsandblack       2\n",
       "luvsephora77       2\n",
       "kaylabeth90        2\n",
       "dlynn009           2\n",
       "maskofshelley      1\n",
       "Name: UserNickname, Length: 51813, dtype: int64"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_vanilla_clean.UserNickname.value_counts()[:51813]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_sample = [i for i in df_vanilla_clean.UserNickname.value_counts()[:51813].to_frame().index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vanilla_sample = df_vanilla_clean[df_vanilla_clean.UserNickname.isin(users_sample)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-366-4705d85d8202>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_vanilla_sample['Rating_bin'] = np.where(df_vanilla_sample['Rating']>2, 1, 0).astype(int)\n"
     ]
    }
   ],
   "source": [
    "df_vanilla_sample['Rating_bin'] = np.where(df_vanilla_sample['Rating']>2, 1, 0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vanilla_sample_matrix = df_vanilla_sample.pivot(index='UserNickname', \n",
    "                    columns='ProductId', values = 'Rating_bin').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = Reader(rating_scale=(0, 1))\n",
    "datasample_bin = Dataset.load_from_df(df_vanilla_sample[['UserNickname', 'ProductId', 'Rating_bin']], reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building SVDpp model\n",
    "\n",
    "trainset, testset = train_test_split(datasample_bin, test_size = 0.3)\n",
    "alg = SVDpp(n_epochs = 25, lr_all = 0.005, reg_all = 0.4)\n",
    "alg.fit(trainset)\n",
    "test_pred = alg.test(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "real = []\n",
    "pred = []\n",
    "for i in range(len(testset)):\n",
    "    r = testset[i][2]\n",
    "    p = test_pred[i][3]\n",
    "    real.append(r)\n",
    "    pred.append(p)\n",
    "\n",
    "# Predictions are continuous\n",
    "# Used 0.5 as a threshold, >0.5 as recommending, <0.5 as not recommending\n",
    "pred_bin = []\n",
    "for i in range(len(test_pred)):\n",
    "    predbin = np.where(test_pred[i][3]>0.6, 1, 0)\n",
    "    pred_bin.append(predbin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.882 \n",
      "ROC AUC Score:, 0.507 \n",
      "Precision Score: 0.883 \n",
      "Recall Score: 0.998\n"
     ]
    }
   ],
   "source": [
    "acu_bo = accuracy_score(real, pred_bin)\n",
    "auc_bo = roc_auc_score(real, pred_bin, average='weighted')\n",
    "prec_bo = precision_score(real, pred_bin)\n",
    "rec_bo = recall_score(real, pred_bin)\n",
    "print('Accuracy Score:', '{:.3f}'.format(acu_bo), \n",
    "      '\\nROC AUC Score:, ''{:.3f}'.format(auc_bo),\n",
    "      '\\nPrecision Score:', '{:.3f}'.format(prec_bo), \n",
    "      '\\nRecall Score:', '{:.3f}'.format(rec_bo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting a sample of 50 users\n",
    "ta_1 = defaultdict(list)\n",
    "\n",
    "for iid in df_vanilla_sample_matrix.columns:\n",
    "    df_1 = pd.DataFrame()\n",
    "    for uid in df_vanilla_sample_matrix.index[:50]:\n",
    "        est = alg.predict(uid, iid)\n",
    "        ta_1[uid].append(est)\n",
    "        a = pd.DataFrame(ta_1[uid], columns = ['uid', 'iid', 'r_ui', 'est', 'details'])\n",
    "        df_1 = pd.concat([a, df_1])\n",
    "df_1.to_csv('prediction_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>UserNickname</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Rating_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>119043</th>\n",
       "      <td>120735</td>\n",
       "      <td>13bananas</td>\n",
       "      <td>P442842</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298056</th>\n",
       "      <td>301877</td>\n",
       "      <td>13bananas</td>\n",
       "      <td>P442846</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0 UserNickname ProductId  Rating  Rating_bin\n",
       "119043      120735    13bananas   P442842       5           1\n",
       "298056      301877    13bananas   P442846       5           1"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_vanilla_clean_13bananas = df_vanilla_clean[df_vanilla_clean.UserNickname == '13bananas']\n",
    "df_vanilla_clean_13bananas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['13bananas', '13Napier', '1337', '1331', '131oz', '1273natkb',\n",
       "       '124598', '123lauryn', '123cantho', '123beautyinside', '123Mandy',\n",
       "       '123Beautylove', '123AllyC', '1234kat', '1234Anna', '1234Abby',\n",
       "       '1234567899', '11Makeup11', '118makeupjunkie', '1125dmw', '110011',\n",
       "       '1083', '103368', '100natalia', '100Pris', '1000attempts', '1-jan',\n",
       "       '0verthestars', '0tter99', '0smoky0', '0nicolee', '0l1ve',\n",
       "       '0clare0', '0Brielle', '093008130306', '090913', '07Amanda',\n",
       "       '0508angela1995', '0415KM', '0392amanda', '0305lovelyone',\n",
       "       '00hatter', '00avancer', '00Nicole', '007gal', '007CatWomen',\n",
       "       '007Barbie', '005leafs', '001000101', '00022'], dtype=object)"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_50 = pd.read_csv('prediction_1.csv')\n",
    "user_50_compare = user_50.merge(df_vanilla_clean, left_on = ['uid', 'iid'],\n",
    "                    right_on = ['UserNickname', 'ProductId'], how = 'left')\n",
    "user_50_compare = user_50_compare.drop(['Unnamed: 0_x', 'r_ui', 'details', \n",
    "                        'Unnamed: 0_y', 'UserNickname', 'ProductId', 'Rating'], axis=1)\n",
    "user_50_compare['Rating_bin'] = user_50_compare['Rating_bin'].fillna(-1)\n",
    "user_50_compare.uid.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Making a function for getting new recommendations\n",
    "def new_recommendations(userid, database_pred):\n",
    "    df_lookup = database_pred[database_pred.uid.isin([userid])].sort_values(by=['Rating_bin', 'est'], ascending=False)\n",
    "    df_purchased = df_lookup[df_lookup.Rating_bin == 1]\n",
    "    df_topnew = df_lookup[(df_lookup.Rating_bin == -1)][:5]\n",
    "    \n",
    "    purchased = []\n",
    "    \n",
    "    new_rec = []\n",
    "    \n",
    "    product_name_purchased = df_pro[df_pro.Product_pid.isin(df_purchased['iid'].unique())]\n",
    "    \n",
    "    product_name_purchased['complete'] = product_name_purchased['brand'] + \" - \" + product_name_purchased['product_name']\n",
    "    \n",
    "    purchased.append(product_name_purchased['complete'])\n",
    "    \n",
    "    product_name_new = df_pro[df_pro.Product_pid.isin(df_topnew['iid'].unique())]\n",
    "    \n",
    "    product_name_new['complete'] = product_name_new['brand'] + \" - \" + product_name_new['product_name']\n",
    "    \n",
    "    new_rec = [product_name_new['complete']]\n",
    "    \n",
    "    print('Hello!', userid)\n",
    "    print('\\nIt seems you like:\\n', '\\n', purchased[:][0])\n",
    "    print('\\nWe think you might also like \\n', '\\n', new_rec[:][0])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! 118makeupjunkie\n",
      "\n",
      "It seems you like:\n",
      " \n",
      " 91     Herbivore - Blue Tansy BHA and Enzyme Pore Ref...\n",
      "101                             Caudalie - Beauty Elixir\n",
      "492       Herbivore - Citrine Glowing Hydration Body Oil\n",
      "Name: complete, dtype: object\n",
      "\n",
      "We think you might also like \n",
      " \n",
      " 264            fresh - Hesperides Grapefruit Body Lotion\n",
      "475    Skinfix - Redness Recovery+ Antioxidant Eye Tr...\n",
      "536            Saint Jane Beauty - Luxury CBD Body Serum\n",
      "646         KORRES - Greek Yoghurt Calming + Cooling Gel\n",
      "647                     Omorovicza - Moor Cream Cleanser\n",
      "Name: complete, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-309-ddc386cf1543>:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  product_name_purchased['complete'] = product_name_purchased['brand'] + \" - \" + product_name_purchased['product_name']\n",
      "<ipython-input-309-ddc386cf1543>:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  product_name_new['complete'] = product_name_new['brand'] + \" - \" + product_name_new['product_name']\n"
     ]
    }
   ],
   "source": [
    "new_recommendations('118makeupjunkie', user_50_compare)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LightFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_product_select = pd.read_csv('Final_product_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_product_fts = df_product_select[['Product_pid', 'Awards', 'Clinical_tested']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_product_matrix = df_product_fts.set_index('Product_pid').sort_index(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Awards</th>\n",
       "      <th>Clinical_tested</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Product_pid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>P100101</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P12045</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P12295</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P12336</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P152203</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Awards  Clinical_tested\n",
       "Product_pid                         \n",
       "P100101           0                0\n",
       "P12045            0                1\n",
       "P12295            0                1\n",
       "P12336            0                1\n",
       "P152203           0                0"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_product_matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = scipy.sparse.csr_matrix(df_vanilla_matrix)\n",
    "data_bin = scipy.sparse.csr_matrix(df_vanilla_matrix_binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vanilla "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7956745\n",
      "0.1646646508093749\n",
      "0.018723162\n"
     ]
    }
   ],
   "source": [
    "# Vanilla\n",
    "# Original Rating\n",
    "train, test = cross_validation.random_train_test_split(data, test_percentage=0.3, random_state=12345)\n",
    "model = LightFM(loss = 'warp', no_components = 8)\n",
    "model.fit(train, epochs=25)\n",
    "print(auc_score(model, test, train).mean())\n",
    "print(recall_at_k(model, test, train).mean())\n",
    "print(precision_at_k(model, test, train).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8030535\n",
      "0.17642505577734202\n",
      "0.01975212\n"
     ]
    }
   ],
   "source": [
    "# Vanilla binary data\n",
    "# Rating 1 or 2 will be 0\n",
    "train, test = cross_validation.random_train_test_split(data_bin, test_percentage=0.3, random_state=12345)\n",
    "model = LightFM(loss = 'warp', no_components = 8)\n",
    "model.fit(train, epochs=25)\n",
    "print(auc_score(model, test, train).mean())\n",
    "print(recall_at_k(model, test, train).mean())\n",
    "print(precision_at_k(model, test, train).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding user features only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rating_users = df_rating[['UserNickname', 'ProductId', 'Rating', 'skintype', 'skinconcerns', 'skintone']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rating_cleanuser = df_rating_users.drop_duplicates(subset=['UserNickname', 'ProductId']).dropna(subset=['UserNickname']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_user_item = df_rating_cleanuser.pivot(index='UserNickname', \n",
    "                    columns='ProductId', values = 'Rating').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_feature = pd.get_dummies(df_rating_cleanuser[['skintype', 'skinconcerns', 'skintone']]).reset_index(drop=True)\n",
    "df_user_feature = df_rating_cleanuser[['UserNickname']].join(user_feature).drop_duplicates(subset=['UserNickname'])\n",
    "user_matrix = df_user_feature.set_index('UserNickname').sort_index(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "userfeature = scipy.sparse.csr_matrix(user_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8728628\n",
      "0.21176798242409894\n",
      "0.023229467\n"
     ]
    }
   ],
   "source": [
    "# Model adding user feature\n",
    "train, test = cross_validation.random_train_test_split(data_bin, test_percentage=0.3, random_state=12345)\n",
    "model = LightFM(loss = 'warp', no_components = 8)\n",
    "model.fit(train, user_features = userfeature, epochs=25)\n",
    "print(auc_score(model, test, train_interactions=train, user_features = userfeature).mean())\n",
    "print(recall_at_k(model, test, train_interactions=train, user_features = userfeature).mean())\n",
    "print(precision_at_k(model, test, train_interactions=train, user_features = userfeature).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.83250934\n",
      "0.13134598027930178\n",
      "0.017620146\n"
     ]
    }
   ],
   "source": [
    "# Model adding user feature and excluding users with only one reviews\n",
    "sample_bin = scipy.sparse.csr_matrix(df_vanilla_sample_matrix)\n",
    "train, test = cross_validation.random_train_test_split(sample_bin, test_percentage=0.3, random_state=12345)\n",
    "model = LightFM(loss = 'warp', no_components = 8)\n",
    "model.fit(train, user_features = userfeature, epochs=25)\n",
    "print(auc_score(model, test, train_interactions=train, user_features = userfeature).mean())\n",
    "print(recall_at_k(model, test, train_interactions=train, user_features = userfeature).mean())\n",
    "print(precision_at_k(model, test, train_interactions=train, user_features = userfeature).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding item features only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing products info\n",
    "df_pro.columns\n",
    "df_product_select_clean = df_pro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_product_select_clean['all_kw'] = df_product_select_clean[['brand', 'product_name', \n",
    "                                                             'product_type', 'ingred_list']].agg(','.join, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prod_m_c = df_product_select_clean[['Product_pid','all_kw']].set_index('Product_pid').sort_index(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF Vector, LightFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = TfidfVectorizer(analyzer='word', ngram_range=(1, 3), min_df=0, stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_prod = tf.fit_transform(df_prod_m_c['all_kw'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "itemfeature = scipy.sparse.csr_matrix(matrix_prod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.78690624\n",
      "0.17197407735850423\n",
      "0.019662488\n"
     ]
    }
   ],
   "source": [
    "train, test = cross_validation.random_train_test_split(data_bin, test_percentage=0.3, random_state=12345)\n",
    "model = LightFM(loss = 'warp', no_components = 8)\n",
    "model.fit(train, item_features = itemfeature, epochs=25)\n",
    "print(auc_score(model, test, train_interactions=train,\n",
    "            item_features = itemfeature).mean())\n",
    "print(recall_at_k(model, test, train_interactions=train, \n",
    "            item_features = itemfeature).mean())\n",
    "print(precision_at_k(model, test, train_interactions=train, \n",
    "            item_features = itemfeature).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count Vector, LightFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = CountVectorizer()\n",
    "count_matrix = count.fit_transform(df_product_select_clean['all_kw'])\n",
    "\n",
    "# generating the cosine similarity matrix\n",
    "# cosine_sim = cosine_similarity(count_matrix, count_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8101676\n",
      "0.8759591\n",
      "0.13897170258104366\n",
      "0.0152482325\n"
     ]
    }
   ],
   "source": [
    "model = LightFM(loss = 'warp', no_components = 8)\n",
    "model.fit(train, item_features = count_matrix, epochs=25)\n",
    "print(auc_score(model, test, train_interactions=train,\n",
    "            item_features = count_matrix).mean())\n",
    "\n",
    "print(recall_at_k(model, test, train_interactions=train, \n",
    "            item_features = count_matrix).mean())\n",
    "print(precision_at_k(model, test, train_interactions=train, \n",
    "            item_features = count_matrix).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF, pairwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rating = pd.read_csv('product_ratings_customer.csv')\n",
    "df_rating['skintype'] = df_rating['skintype'].replace('No info', 'Unknown')\n",
    "df_rating['skinconcerns'] = df_rating['skinconcerns'].replace('No info', 'Unknown')\n",
    "df_rating['skintone'] = df_rating['skintone'].replace('No info', 'Unknown')\n",
    "df_rating['all_kw'] = df_rating[['skintype', 'skintone', 'skinconcerns']].agg(','.join, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Badges</th>\n",
       "      <th>BadgesOrder</th>\n",
       "      <th>ContentLocale</th>\n",
       "      <th>ContextDataValues</th>\n",
       "      <th>ContextDataValuesOrder</th>\n",
       "      <th>Id</th>\n",
       "      <th>IsRatingsOnly</th>\n",
       "      <th>IsRecommended</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>...</th>\n",
       "      <th>TotalPositiveFeedbackCount</th>\n",
       "      <th>UserNickname</th>\n",
       "      <th>Dict_context</th>\n",
       "      <th>skintype</th>\n",
       "      <th>eyecolor</th>\n",
       "      <th>skinconcerns</th>\n",
       "      <th>haircolor</th>\n",
       "      <th>skintone</th>\n",
       "      <th>review_kw</th>\n",
       "      <th>all_kw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>{}</td>\n",
       "      <td>[]</td>\n",
       "      <td>en_US</td>\n",
       "      <td>{'skinType': {'Value': 'combination', 'Id': 's...</td>\n",
       "      <td>['eyeColor', 'hairColor', 'skinTone', 'skinTyp...</td>\n",
       "      <td>117129210</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>P420224</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>lizziebae</td>\n",
       "      <td>{'skinType': {'Value': 'combination', 'Id': 's...</td>\n",
       "      <td>Combination</td>\n",
       "      <td>Green</td>\n",
       "      <td>Acne</td>\n",
       "      <td>Blonde</td>\n",
       "      <td>Fair</td>\n",
       "      <td>['really', 'liked', 'product', 'made', 'skin',...</td>\n",
       "      <td>Combination,Fair,Acne</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>{}</td>\n",
       "      <td>[]</td>\n",
       "      <td>en_US</td>\n",
       "      <td>{'skinType': {'Value': 'combination', 'Id': 's...</td>\n",
       "      <td>['eyeColor', 'hairColor', 'skinTone', 'skinTyp...</td>\n",
       "      <td>156143419</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>P420224</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>BelleOh</td>\n",
       "      <td>{'skinType': {'Value': 'combination', 'Id': 's...</td>\n",
       "      <td>Combination</td>\n",
       "      <td>Brown</td>\n",
       "      <td>Aging</td>\n",
       "      <td>Blonde</td>\n",
       "      <td>Fair</td>\n",
       "      <td>['using', 'essence', 'recently', 'ran', 'notic...</td>\n",
       "      <td>Combination,Fair,Aging</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>{}</td>\n",
       "      <td>[]</td>\n",
       "      <td>en_US</td>\n",
       "      <td>{'skinType': {'Value': 'dry', 'Id': 'skinType'...</td>\n",
       "      <td>['eyeColor', 'hairColor', 'skinTone', 'skinTyp...</td>\n",
       "      <td>137182034</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>P420224</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>BelLaCafe</td>\n",
       "      <td>{'skinType': {'Value': 'dry', 'Id': 'skinType'...</td>\n",
       "      <td>Dry</td>\n",
       "      <td>Brown</td>\n",
       "      <td>Acne</td>\n",
       "      <td>Brunette</td>\n",
       "      <td>Olive</td>\n",
       "      <td>['lightly', 'exfoliates', 'surface', 'skin', '...</td>\n",
       "      <td>Dry,Olive,Acne</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>{}</td>\n",
       "      <td>[]</td>\n",
       "      <td>en_US</td>\n",
       "      <td>{'skinType': {'Value': 'combination', 'Id': 's...</td>\n",
       "      <td>['eyeColor', 'hairColor', 'skinTone', 'skinTyp...</td>\n",
       "      <td>126600083</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>P420224</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>bluekrait</td>\n",
       "      <td>{'skinType': {'Value': 'combination', 'Id': 's...</td>\n",
       "      <td>Combination</td>\n",
       "      <td>Brown</td>\n",
       "      <td>Acne</td>\n",
       "      <td>Brunette</td>\n",
       "      <td>Medium</td>\n",
       "      <td>['vinoperfect', 'line', 'diminished', 'dark', ...</td>\n",
       "      <td>Combination,Medium,Acne</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>{}</td>\n",
       "      <td>[]</td>\n",
       "      <td>en_US</td>\n",
       "      <td>{}</td>\n",
       "      <td>[]</td>\n",
       "      <td>104184861</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>P420224</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>fairginger</td>\n",
       "      <td>{}</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>No info</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>No info</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>['literally', 'holy', 'grail', 'there', 'notic...</td>\n",
       "      <td>Unknown,Unknown,Unknown</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 Badges BadgesOrder ContentLocale  \\\n",
       "0           0     {}          []         en_US   \n",
       "1           1     {}          []         en_US   \n",
       "2           2     {}          []         en_US   \n",
       "3           3     {}          []         en_US   \n",
       "4           4     {}          []         en_US   \n",
       "\n",
       "                                   ContextDataValues  \\\n",
       "0  {'skinType': {'Value': 'combination', 'Id': 's...   \n",
       "1  {'skinType': {'Value': 'combination', 'Id': 's...   \n",
       "2  {'skinType': {'Value': 'dry', 'Id': 'skinType'...   \n",
       "3  {'skinType': {'Value': 'combination', 'Id': 's...   \n",
       "4                                                 {}   \n",
       "\n",
       "                              ContextDataValuesOrder         Id  \\\n",
       "0  ['eyeColor', 'hairColor', 'skinTone', 'skinTyp...  117129210   \n",
       "1  ['eyeColor', 'hairColor', 'skinTone', 'skinTyp...  156143419   \n",
       "2  ['eyeColor', 'hairColor', 'skinTone', 'skinTyp...  137182034   \n",
       "3  ['eyeColor', 'hairColor', 'skinTone', 'skinTyp...  126600083   \n",
       "4                                                 []  104184861   \n",
       "\n",
       "   IsRatingsOnly  IsRecommended ProductId  ...  TotalPositiveFeedbackCount  \\\n",
       "0          False            1.0   P420224  ...                          10   \n",
       "1          False            1.0   P420224  ...                           7   \n",
       "2          False            1.0   P420224  ...                           1   \n",
       "3          False            1.0   P420224  ...                           3   \n",
       "4          False            1.0   P420224  ...                           4   \n",
       "\n",
       "  UserNickname                                       Dict_context  \\\n",
       "0    lizziebae  {'skinType': {'Value': 'combination', 'Id': 's...   \n",
       "1      BelleOh  {'skinType': {'Value': 'combination', 'Id': 's...   \n",
       "2    BelLaCafe  {'skinType': {'Value': 'dry', 'Id': 'skinType'...   \n",
       "3    bluekrait  {'skinType': {'Value': 'combination', 'Id': 's...   \n",
       "4   fairginger                                                 {}   \n",
       "\n",
       "      skintype eyecolor  skinconcerns  haircolor skintone  \\\n",
       "0  Combination    Green          Acne     Blonde     Fair   \n",
       "1  Combination    Brown         Aging     Blonde     Fair   \n",
       "2          Dry    Brown          Acne   Brunette    Olive   \n",
       "3  Combination    Brown          Acne   Brunette   Medium   \n",
       "4      Unknown  No info       Unknown    No info  Unknown   \n",
       "\n",
       "                                           review_kw                   all_kw  \n",
       "0  ['really', 'liked', 'product', 'made', 'skin',...    Combination,Fair,Acne  \n",
       "1  ['using', 'essence', 'recently', 'ran', 'notic...   Combination,Fair,Aging  \n",
       "2  ['lightly', 'exfoliates', 'surface', 'skin', '...           Dry,Olive,Acne  \n",
       "3  ['vinoperfect', 'line', 'diminished', 'dark', ...  Combination,Medium,Acne  \n",
       "4  ['literally', 'holy', 'grail', 'there', 'notic...  Unknown,Unknown,Unknown  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rating.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rating = df_rating.sort_values(by=['UserNickname', 'all_kw']).reset_index(drop=True).dropna(subset=['UserNickname'])\n",
    "df_rating = df_rating.drop_duplicates(subset=['UserNickname'], keep='first').reset_index(drop=True)\n",
    "df_rating_user = df_rating[['UserNickname', 'all_kw']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Item similarities\n",
    "tf = TfidfVectorizer(analyzer='word', ngram_range=(1, 3), min_df=0, stop_words='english')\n",
    "matrix_prod = tf.fit_transform(df_prod_m_c['all_kw'])\n",
    "cosine_sim2 = cosine_similarity(matrix_prod, matrix_prod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.00000000e+00, 1.15265316e-01, 8.45969825e-02, ...,\n",
       "        9.00738814e-02, 3.43559169e-02, 2.01729159e-02],\n",
       "       [1.15265316e-01, 1.00000000e+00, 4.60154416e-02, ...,\n",
       "        2.07237874e-03, 4.72178723e-03, 9.21458555e-03],\n",
       "       [8.45969825e-02, 4.60154416e-02, 1.00000000e+00, ...,\n",
       "        1.03733604e-01, 4.62912716e-02, 2.20831903e-02],\n",
       "       ...,\n",
       "       [9.00738814e-02, 2.07237874e-03, 1.03733604e-01, ...,\n",
       "        1.00000000e+00, 6.02581902e-02, 3.68133045e-04],\n",
       "       [3.43559169e-02, 4.72178723e-03, 4.62912716e-02, ...,\n",
       "        6.02581902e-02, 1.00000000e+00, 2.30351099e-02],\n",
       "       [2.01729159e-02, 9.21458555e-03, 2.20831903e-02, ...,\n",
       "        3.68133045e-04, 2.30351099e-02, 1.00000000e+00]])"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_sim2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User + Item features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lightfm.lightfm.LightFM at 0x7fcfd037e700>"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LightFM(loss = 'warp', no_components = 8)\n",
    "model.fit(train, user_features = userfeature, item_features = count_matrix, epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.86253625\n",
      "0.9260204\n",
      "0.1971664428593215\n",
      "0.021649744\n"
     ]
    }
   ],
   "source": [
    "print(auc_score(model, test, train_interactions=train, user_features = userfeature,\n",
    "            item_features = count_matrix).mean())\n",
    "print(np.median(auc_score(model, test, train_interactions=train, user_features = userfeature,\n",
    "                         item_features = count_matrix)))\n",
    "\n",
    "print(recall_at_k(model, test, train_interactions=train,  user_features = userfeature,\n",
    "            item_features = count_matrix).mean())\n",
    "print(precision_at_k(model, test, train_interactions=train, user_features = userfeature,\n",
    "            item_features = count_matrix).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendation Display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-129.59239, -129.59239], dtype=float32)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(np.array([0,0]), np.array([1, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = [10, 11, 12]\n",
    "items = [76, 75]\n",
    "array_u = []\n",
    "array_i = []\n",
    "for user in users: \n",
    "    array_u += 2 * [user]\n",
    "        \n",
    "array_i = np.array([items]).repeat(3, axis=0).reshape(1,len(array_u))[0,:]\n",
    "    #array_i.append([x] * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([10, 10, 11, 11, 12, 12], array([76, 75, 76, 75, 76, 75]))"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_u, array_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations(model, data, users, items):\n",
    "    \n",
    "    nu = len(users)\n",
    "    ni = len(items)\n",
    "    \n",
    "    array_u = []\n",
    "    array_i = []\n",
    "    \n",
    "    for user in users: \n",
    "        array_u += ni * [user]\n",
    "        \n",
    "    array_i = np.array([items]).repeat(nu, axis=0).reshape(1, len(array_u))[0,:]\n",
    "  \n",
    "    rec_scores = model.predict(np.array(array_u), array_i)\n",
    "    \n",
    "    re_reshape = rec_scores.reshape(nu, ni)\n",
    "    \n",
    "    for i in range(len(users)):\n",
    "        \n",
    "        print(users[i], ,'has a top choice:',\n",
    "              data_user_item.columns[items[np.argmax(re_reshape[i])]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 has a top choice: P380805\n",
      "11 has a top choice: P380805\n"
     ]
    }
   ],
   "source": [
    "get_recommendations(model, test, [10, 11], [76, 75])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
